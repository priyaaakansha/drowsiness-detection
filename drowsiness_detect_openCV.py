# -*- coding: utf-8 -*-
"""Final_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kma1lAAWVzU6ozm1eusL_igkOXvgQ1CJ
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
import cv2
import os
# %matplotlib inline

img = cv2.imread("/content/drive/MyDrive/Colab Notebooks/FD/Closed_Eyes/s0001_00001_0_0_0_0_0_01.png",cv2.IMREAD_GRAYSCALE)

plt.imshow(img,cmap="gray")

img.shape

Datadirectory="/content/drive/MyDrive/Colab Notebooks/FD"
Classes=["Closed_Eyes","Open_Eyes"]
for category in Classes:
    path=os.path.join(Datadirectory, category)
    for imgs in os.listdir(path):
        img=cv2.imread(os.path.join(path,imgs),cv2.IMREAD_GRAYSCALE)
        backtorgb=cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)
        plt.imshow(img,cmap="gray")
        plt.show()
        break
    break

img_size=224
img=cv2.resize(backtorgb,(img_size,img_size))
plt.imshow(img,cmap='gray')
plt.show()

training_Data = []

def create_training_Data():
  for category in Classes:
    path=os.path.join(Datadirectory, category)
    class_num=Classes.index(category)
    print(class_num)
    for img in os.listdir(path):
      try:
        img_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)
        backtorgb=cv2.cvtColor(img_array,cv2.COLOR_GRAY2BGR)
        new_array=cv2.resize(backtorgb,(img_size,img_size))
        training_Data.append([new_array,class_num])
      except Exception as e:
        pass



create_training_Data()

print(len(training_Data))

import random
random.shuffle(training_Data)

X=[]
Y=[]

for features,label in training_Data:
  X.append(features)
  Y.append(label)

X=np.array(X).reshape(-1,img_size,img_size,3)

X.shape

X=X/255.0

Y=np.array(Y)

print(Y)



import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

model=tf.keras.applications.mobilenet.MobileNet()

model.summary()

# Transfer Learning

base_input=model.layers[0].input

base_output=model.layers[-4].output

Flat_layer=layers.Flatten()(base_output)
final_output=layers.Dense(1)(Flat_layer)
final_output=layers.Activation('sigmoid')(final_output)

new_model=keras.Model(inputs=base_input, outputs=final_output)

new_model.summary()

#settings for binary classification

new_model.compile(loss="binary_crossentropy",optimizer="adam",metrics=["Accuracy"])

new_model.fit(X,Y,epochs=10, validation_split=0.1)

new_model.save('my_model.h5')

#checking model accuracy

img_array=cv2.imread("/content/drive/MyDrive/Colab Notebooks/FD/Open_Eyes/s0001_01901_0_0_1_0_0_01.png",cv2.IMREAD_GRAYSCALE)
backtorgb=cv2.cvtColor(img_array, cv2.COLOR_GRAY2BGR)
new_array=cv2.resize(backtorgb,(img_size,img_size))

X_input=np.array(new_array).reshape(1,img_size,img_size,3)

X_input.shape

X_input=X_input/255.0

plt.imshow(new_array)

prediction=new_model.predict(X_input)

prediction

img_array=cv2.imread("/content/drive/MyDrive/Colab Notebooks/Dataset/Closed_Eyes/s0001_00134_0_0_0_0_0_01.png",cv2.IMREAD_GRAYSCALE)
backtorgb=cv2.cvtColor(img_array, cv2.COLOR_GRAY2BGR)
new_array=cv2.resize(backtorgb,(img_size,img_size))

X_input=np.array(new_array).reshape(1,img_size,img_size,3)
X_input=X_input/255.0
X_input.shape

plt.imshow(new_array)

prediction=new_model.predict(X_input)
prediction

import cv2 ##pip install opencv-python
## pip install opency-contrib-python fullpackage
#from deepface import DeepFace # pip install deepfoce path = "haarcascade_frontalface default.xml"

faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')

cap=cv2.VideoCapture(1)
#Check if the webcom is opened correctly
if not cap.isOpened():
    cap=cv2.VideoCapture(0)
if not cap.isOpened():
    raise IOError("Cannot open webcam")

while True:
    ret, frame=cap.read()
    eye_cascade=cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_eye.xml')
    gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    #print (faceCascade.empty())
    eyes=eye_cascade.detectMultiScale(gray,1.1,4) 
    for x,y,w,h in eyes:
        roi_gray=gray[y:y+h, x:x+w]
        roi_color=frame[y:y+h, x:x+w]
        cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 255, 0), 2)
        eyess = eye_cascade.detectMultiScale(roi_gray)
        if len(eyess)==0:
            print("eyes are not detected")
        else:
            for (ex, ey, ew, eh) in eyess:
                eyes_roi = roi_color[ey: ey+eh, ex: ex+ew]

    final_image=cv2.resize(eyes_roi, (224,224))
    final_image = np.expand_dims(final_image, axis=0)## need fourth dimension
    final_image=final_image/255.0

    Predictions = model.predict(final_image)
    if(Predictions>0.5): 
        status="Open Eyes"
    else:
        status="Closed Eyes"

    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)
    print(faceCascade.empty())
    faces=faceCascade.detectMultiScale(gray,1.1,4)

    #draw a rectangle around the faces
    for(x,y,w,h) in faces:
        cv2.rectangle(frame, (x,y),(x+w , y+h),(0, 255, 0),2)

    font=cv2.FONT_HERSHEY_SIMPLEX

    #use putText() method for
    #inserting text in video

    cv2.putText(frame,status,(50,50),font,3,(0,0,255),2,cv2.LINE_4)
    cv2.imshow('Drowsiness Detection',frame)

    if cv2.waitKey(2) & 0xFF == ord('q'):
        break
    
cap.release()
cv2.destroyAllWindows()

